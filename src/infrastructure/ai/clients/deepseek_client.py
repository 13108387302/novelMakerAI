#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DeepSeekå®¢æˆ·ç«¯å®ç°

æä¾›DeepSeek APIçš„å®¢æˆ·ç«¯å®ç°
"""

import asyncio
import logging
from typing import Dict, Any, Optional, AsyncGenerator, List
import openai
from openai import AsyncOpenAI

from .base_ai_client import BaseAIClient
from src.domain.ai.entities.ai_request import AIRequest
from src.domain.ai.entities.ai_response import AIResponse, AIResponseStatus
from src.domain.ai.value_objects.ai_capability import AICapability
from src.shared.constants import (
    AI_TIMEOUT_SECONDS, AI_MAX_TOKENS, AI_TEMPERATURE
)

logger = logging.getLogger(__name__)

# DeepSeekå®¢æˆ·ç«¯å¸¸é‡
DEFAULT_DEEPSEEK_BASE_URL = 'https://api.deepseek.com/v1'
DEFAULT_DEEPSEEK_MODEL = 'deepseek-chat'
DEFAULT_MAX_TOKENS = AI_MAX_TOKENS
DEFAULT_TEMPERATURE = AI_TEMPERATURE
SYSTEM_ROLE = "system"
USER_ROLE = "user"
TEST_MAX_TOKENS = 1
CONNECTION_TIMEOUT = AI_TIMEOUT_SECONDS
API_KEY_ERROR_MSG = "DeepSeek APIå¯†é’¥æœªé…ç½®"
CLIENT_NOT_CONNECTED_MSG = "DeepSeekå®¢æˆ·ç«¯æœªè¿æ¥"
CLIENT_NOT_INITIALIZED_MSG = "å®¢æˆ·ç«¯æœªåˆå§‹åŒ–"


class DeepSeekClient(BaseAIClient):
    """
    DeepSeekå®¢æˆ·ç«¯å®ç°
    
    æä¾›DeepSeek APIçš„å®Œæ•´å®¢æˆ·ç«¯åŠŸèƒ½
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        
        Args:
            config: é…ç½®ä¿¡æ¯ï¼ŒåŒ…å«APIå¯†é’¥ç­‰
        """
        super().__init__("deepseek", config)
        
        # DeepSeeké…ç½®
        self.api_key = config.get('api_key', '')
        self.base_url = config.get('base_url', DEFAULT_DEEPSEEK_BASE_URL)
        self.default_model = config.get('default_model', DEFAULT_DEEPSEEK_MODEL)
        self.max_tokens = config.get('max_tokens', DEFAULT_MAX_TOKENS)
        self.temperature = config.get('temperature', DEFAULT_TEMPERATURE)
        
        # å®¢æˆ·ç«¯å®ä¾‹
        self.client: Optional[AsyncOpenAI] = None
        
        # æ”¯æŒçš„èƒ½åŠ›
        self._capabilities = [
            AICapability.TEXT_GENERATION,
            AICapability.CONVERSATION,
            AICapability.CREATIVE_WRITING,
            AICapability.TEXT_ANALYSIS,
            AICapability.TEXT_OPTIMIZATION,
            AICapability.TEXT_SUMMARIZATION,
            AICapability.LANGUAGE_TRANSLATION,
            AICapability.QUESTION_ANSWERING,
            AICapability.STREAMING_OUTPUT,
            AICapability.CONTEXT_AWARENESS,
            AICapability.CREATIVE_INSPIRATION
        ]
    
    async def connect(self) -> bool:
        """
        è¿æ¥åˆ°DeepSeekæœåŠ¡
        
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            if not self.api_key:
                raise ValueError("DeepSeek APIå¯†é’¥æœªé…ç½®")
            
            # åˆ›å»ºå¼‚æ­¥å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨OpenAIå…¼å®¹æ¥å£ï¼‰
            self.client = AsyncOpenAI(
                api_key=self.api_key,
                base_url=self.base_url,
                timeout=self.default_timeout
            )
            
            # æµ‹è¯•è¿æ¥
            await self._test_connection()
            
            self.is_connected = True
            logger.info(f"DeepSeekå®¢æˆ·ç«¯è¿æ¥æˆåŠŸ: {self.base_url}")
            return True
            
        except Exception as e:
            self.last_error = str(e)
            self.is_connected = False
            logger.error(f"DeepSeekå®¢æˆ·ç«¯è¿æ¥å¤±è´¥: {e}")
            return False
    
    async def disconnect(self) -> None:
        """æ–­å¼€DeepSeekæœåŠ¡è¿æ¥"""
        if self.client:
            await self.client.close()
            self.client = None
        
        self.is_connected = False
        logger.info("DeepSeekå®¢æˆ·ç«¯å·²æ–­å¼€è¿æ¥")
    
    async def is_healthy(self) -> bool:
        """
        æ£€æŸ¥å®¢æˆ·ç«¯å¥åº·çŠ¶æ€
        
        Returns:
            bool: æ˜¯å¦å¥åº·
        """
        if not self.is_connected or not self.client:
            return False
        
        try:
            # ç®€å•çš„å¥åº·æ£€æŸ¥
            await self._test_connection()
            return True
        except Exception as e:
            logger.warning(f"DeepSeekå®¢æˆ·ç«¯å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def get_capabilities(self) -> List[AICapability]:
        """
        è·å–å®¢æˆ·ç«¯æ”¯æŒçš„èƒ½åŠ›
        
        Returns:
            List[AICapability]: æ”¯æŒçš„èƒ½åŠ›åˆ—è¡¨
        """
        return self._capabilities.copy()
    
    async def generate_text(
        self,
        request: AIRequest,
        timeout: Optional[float] = None
    ) -> AIResponse:
        """
        ç”Ÿæˆæ–‡æœ¬
        
        Args:
            request: AIè¯·æ±‚
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            AIResponse: AIå“åº”
        """
        if not self.client:
            raise RuntimeError("DeepSeekå®¢æˆ·ç«¯æœªè¿æ¥")
        
        try:
            # æ„å»ºæ¶ˆæ¯
            messages = self._build_messages(request)
            
            # è·å–æ¨¡å‹å‚æ•°ï¼ˆå…¼å®¹æ˜¾å¼ä¼ å…¥Noneçš„æƒ…å†µï¼Œå›è½åˆ°é»˜è®¤æ¨¡å‹ï¼‰
            model = request.parameters.get('model') or self.default_model
            max_tokens = request.parameters.get('max_tokens', self.max_tokens)
            temperature = request.parameters.get('temperature', self.temperature)

            # è°ƒç”¨DeepSeek API
            response = await self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                timeout=timeout or self.default_timeout
            )
            
            # æ„å»ºå“åº”
            content = response.choices[0].message.content or ""
            ai_response = AIResponse(
                request_id=request.id,
                content=content,
                status=AIResponseStatus.COMPLETED,
                provider=self.provider_name,
                model=model
            )
            
            # è®¾ç½®è´¨é‡æŒ‡æ ‡
            ai_response.quality_metrics.token_count = response.usage.total_tokens if response.usage else 0
            ai_response.quality_metrics.calculate_content_metrics(content)
            
            return ai_response
            
        except Exception as e:
            logger.error(f"DeepSeekæ–‡æœ¬ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    async def generate_text_stream(
        self,
        request: AIRequest,
        timeout: Optional[float] = None
    ) -> AsyncGenerator[str, None]:
        """
        æµå¼ç”Ÿæˆæ–‡æœ¬
        
        Args:
            request: AIè¯·æ±‚
            timeout: è¶…æ—¶æ—¶é—´
            
        Yields:
            str: æ–‡æœ¬å—
        """
        if not self.client:
            raise RuntimeError("DeepSeekå®¢æˆ·ç«¯æœªè¿æ¥")
        
        try:
            # æ„å»ºæ¶ˆæ¯
            messages = self._build_messages(request)
            
            # è·å–æ¨¡å‹å‚æ•°ï¼ˆå…¼å®¹æ˜¾å¼ä¼ å…¥Noneçš„æƒ…å†µï¼Œå›è½åˆ°é»˜è®¤æ¨¡å‹ï¼‰
            model = request.parameters.get('model') or self.default_model
            max_tokens = request.parameters.get('max_tokens', self.max_tokens)
            temperature = request.parameters.get('temperature', self.temperature)

            # è°ƒç”¨DeepSeekæµå¼API
            stream = await self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                stream=True,
                timeout=timeout or self.stream_timeout
            )
            
            chunk_count = 0
            async for chunk in stream:
                chunk_count += 1
                logger.debug(f"ğŸ”„ DeepSeek chunk {chunk_count}: {chunk}")

                if chunk.choices and chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    logger.debug(f"ğŸ“¦ æå–å†…å®¹: '{content}' (é•¿åº¦: {len(content)})")
                    yield content
                else:
                    logger.debug(f"âš ï¸ ç©ºchunkæˆ–æ— å†…å®¹: choices={bool(chunk.choices)}")

            logger.info(f"âœ… DeepSeekæµå¼ç”Ÿæˆå®Œæˆï¼Œå…±å¤„ç† {chunk_count} ä¸ªchunk")
                    
        except Exception as e:
            logger.error(f"DeepSeekæµå¼ç”Ÿæˆå¤±è´¥: {e}")
            raise
    
    def _build_messages(self, request: AIRequest) -> List[Dict[str, str]]:
        """
        æ„å»ºDeepSeekæ¶ˆæ¯æ ¼å¼
        
        Args:
            request: AIè¯·æ±‚
            
        Returns:
            List[Dict[str, str]]: DeepSeekæ¶ˆæ¯æ ¼å¼
        """
        messages = []
        
        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼ˆå¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼‰
        if request.context:
            messages.append({
                "role": "system",
                "content": f"ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š\n{request.context}"
            })
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": request.prompt
        })
        
        return messages
    
    async def _test_connection(self) -> None:
        """æµ‹è¯•è¿æ¥"""
        if not self.client:
            raise RuntimeError("å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
        
        # å‘é€ç®€å•çš„æµ‹è¯•è¯·æ±‚
        await self.client.chat.completions.create(
            model=self.default_model,
            messages=[{"role": "user", "content": "test"}],
            max_tokens=1,
            timeout=5.0
        )
